"""
SAMæŠ å›¾å·¥å…· - åŸºäºGradioçš„äº¤äº’å¼ç•Œé¢
ä½¿ç”¨Segment Anything Modelå®ç°æ™ºèƒ½æŠ å›¾
"""

import gradio as gr
import numpy as np
from PIL import Image
import torch
import cv2
import os

# å°è¯•å¯¼å…¥segment_anythingï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
try:
    from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator
    SAM_AVAILABLE = True
except ImportError:
    SAM_AVAILABLE = False
    print("è­¦å‘Š: segment_anything åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install segment-anything")

class SAMProcessor:
    """SAMæ¨¡å‹å¤„ç†å™¨"""
    
    def __init__(self):
        self.predictor = None
        self.auto_mask_generator = None
        self.model_loaded = False
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.current_image = None
    
    def _normalize_image_input(self, image):
        """å°†ä»»æ„è¾“å…¥è§„èŒƒåŒ–ä¸º HxWx3 çš„ uint8 è¿ç»­å†…å­˜ RGB å›¾åƒ"""
        try:
            # è·¯å¾„ â†’ PIL
            if isinstance(image, str):
                image = Image.open(image)
            
            # PIL â†’ np.uint8 RGB
            if isinstance(image, Image.Image):
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                image_array = np.array(image)
            else:
                # åˆ—è¡¨/npæ•°ç»„ â†’ npæ•°ç»„
                image_array = np.array(image)
                
                # å¤„ç†dtype
                if image_array.dtype != np.uint8:
                    if np.issubdtype(image_array.dtype, np.floating):
                        image_array = np.clip(image_array * (255.0 if image_array.max() <= 1.0 else 1.0), 0, 255).astype(np.uint8)
                    else:
                        image_array = np.clip(image_array, 0, 255).astype(np.uint8)
            
            # å¤„ç†ç°åº¦ HxW â†’ HxWx3
            if image_array.ndim == 2:
                image_array = np.stack([image_array] * 3, axis=-1)
            
            # å¤„ç†CHW â†’ HWCï¼ˆå¦‚ 3xHxW æˆ– 4xHxWï¼‰
            if image_array.ndim == 3 and image_array.shape[0] in (1, 3, 4) and image_array.shape[0] < image_array.shape[-1]:
                # å¦‚æœ channels åœ¨ç¬¬0ç»´ä¸”è¿œå°äºç©ºé—´ç»´åº¦ï¼Œè§†ä¸ºCHW
                # å†æ¬¡åˆ¤æ–­é¿å…å·²ç»æ˜¯HWCçš„æƒ…å†µ
                if image_array.shape[-1] not in (1, 3, 4):
                    image_array = np.transpose(image_array, (1, 2, 0))
            
            # å»æ‰alphaï¼Œæˆ–æ‰©å±•åˆ°3é€šé“
            if image_array.ndim == 3:
                if image_array.shape[2] == 4:
                    image_array = image_array[:, :, :3]
                elif image_array.shape[2] == 1:
                    image_array = np.repeat(image_array, 3, axis=2)
                elif image_array.shape[2] > 4:
                    image_array = image_array[:, :, :3]
            
            # ç¡®ä¿è¿ç»­å†…å­˜
            image_array = np.ascontiguousarray(image_array, dtype=np.uint8)
            return image_array
        except Exception as e:
            raise RuntimeError(f"å›¾åƒæ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
        
    def load_model(self, model_type="vit_b"):
        """åŠ è½½SAMæ¨¡å‹"""
        if not SAM_AVAILABLE:
            return False, "segment_anything åº“æœªå®‰è£…"
            
        try:
            # æ¨¡å‹æ–‡ä»¶è·¯å¾„
            model_path = f"models/sam_{model_type}.pth"
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_path):
                download_urls = {
                    "vit_b": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth",
                    "vit_l": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth", 
                    "vit_h": "https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
                }
                
                error_msg = f"""
æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}

è¯·ä¸‹è½½æ¨¡å‹æ–‡ä»¶:
1. åˆ›å»º models/ ç›®å½•: mkdir -p models
2. ä¸‹è½½æ¨¡å‹: wget {download_urls[model_type]} -O {model_path}

æˆ–è€…æ‰‹åŠ¨ä¸‹è½½åæ”¾å…¥ models/ ç›®å½•
"""
                return False, error_msg
                
            sam = sam_model_registry[model_type](checkpoint=model_path)
            sam.to(device=self.device)
            self.predictor = SamPredictor(sam)
            # è‡ªåŠ¨åˆ†å‰²ç”Ÿæˆå™¨ï¼ˆæŒ‰éœ€ä½¿ç”¨ï¼‰
            try:
                self.auto_mask_generator = SamAutomaticMaskGenerator(
                    sam,
                    points_per_side=32,
                    pred_iou_thresh=0.86,
                    stability_score_thresh=0.92,
                    crop_n_layers=1,
                    crop_n_points_downscale_factor=2,
                    min_mask_region_area=0
                )
            except Exception as e:
                self.auto_mask_generator = None
            self.model_loaded = True
            return True, f"æ¨¡å‹ {model_type} åŠ è½½æˆåŠŸ!"
            
        except Exception as e:
            return False, f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
    
    def set_image(self, image):
        """è®¾ç½®å½“å‰å›¾åƒ"""
        if not self.model_loaded:
            return False, "æ¨¡å‹æœªåŠ è½½"
            
        try:
            image_array = self._normalize_image_input(image)
            self.predictor.set_image(image_array)
            self.current_image = image_array
            return True, "å›¾åƒè®¾ç½®æˆåŠŸ"
            
        except Exception as e:
            return False, f"å›¾åƒè®¾ç½®å¤±è´¥: {str(e)}"
    
    def predict_with_points(self, points):
        """ä½¿ç”¨ç‚¹å‡»ç‚¹è¿›è¡Œé¢„æµ‹"""
        if not self.model_loaded or self.current_image is None:
            return None, None, "æ¨¡å‹æœªåŠ è½½æˆ–å›¾åƒæœªè®¾ç½®"
            
        try:
            if not points or len(points) == 0:
                return None, None, "è¯·å…ˆåœ¨å›¾åƒä¸Šç‚¹å‡»é€‰æ‹©åŒºåŸŸ"
                
            # è½¬æ¢ç‚¹æ ¼å¼
            input_points = np.array([[p[0], p[1]] for p in points])
            input_labels = np.ones(len(points))  # 1è¡¨ç¤ºå‰æ™¯ç‚¹
            
            # é¢„æµ‹
            masks, scores, logits = self.predictor.predict(
                point_coords=input_points,
                point_labels=input_labels,
                multimask_output=True
            )
            
            # è¿”å›æ‰€æœ‰æ©ç å’Œåˆ†æ•°
            return masks, scores, f"åˆ†å‰²å®Œæˆï¼Œç”Ÿæˆ{len(masks)}ä¸ªå€™é€‰ç»“æœ"
            
        except Exception as e:
            return None, None, f"é¢„æµ‹å¤±è´¥: {str(e)}"

    def auto_segment(self, image):
        """æ— ç‚¹å‡»ç‚¹æ—¶çš„è‡ªåŠ¨åˆ†å‰²ï¼Œè¿”å›æœ€å¤§åŒºåŸŸæ©ç """
        if not self.model_loaded:
            return None, None, "æ¨¡å‹æœªåŠ è½½"
        try:
            # ç”Ÿæˆæ‰€æœ‰å€™é€‰æ©ç 
            if self.auto_mask_generator is None:
                return None, None, "è‡ªåŠ¨åˆ†å‰²ä¸å¯ç”¨"
            masks = self.auto_mask_generator.generate(image)
            if not masks:
                return None, None, "æœªç”Ÿæˆä»»ä½•æ©ç "
            # é€‰æ‹©é¢ç§¯æœ€å¤§çš„æ©ç 
            best = max(masks, key=lambda m: m.get('area', 0))
            best_mask = best.get('segmentation')
            score = best.get('stability_score', 0.0)
            return best_mask, score, f"è‡ªåŠ¨åˆ†å‰²å®Œæˆï¼Œç½®ä¿¡åº¦: {score:.3f}"
        except Exception as e:
            return None, None, f"è‡ªåŠ¨åˆ†å‰²å¤±è´¥: {str(e)}"

def apply_mask_to_image(image, mask, background_transparent=True):
    """å°†æ©ç åº”ç”¨åˆ°å›¾åƒ"""
    if image is None or mask is None:
        return None
        
    try:
        result = image.copy()
        
        if background_transparent:
            # åˆ›å»ºå¸¦é€æ˜èƒŒæ™¯çš„å›¾åƒ
            if len(result.shape) == 3:
                result_rgba = np.zeros((result.shape[0], result.shape[1], 4), dtype=np.uint8)
                result_rgba[:, :, :3] = result
                result_rgba[:, :, 3] = (mask * 255).astype(np.uint8)
                return result_rgba
        else:
            # ç™½è‰²èƒŒæ™¯
            background = np.ones_like(result) * 255
            result = np.where(mask[..., None], result, background)
            
        return result.astype(np.uint8)
        
    except Exception as e:
        return None

# å…¨å±€SAMå¤„ç†å™¨
sam_processor = SAMProcessor()

def load_sam_model(model_type):
    """åŠ è½½SAMæ¨¡å‹çš„åŒ…è£…å‡½æ•°"""
    success, message = sam_processor.load_model(model_type)
    return message


def segment_with_points(display_image, click_coords_text):
    """ä½¿ç”¨æŒ‡å®šåæ ‡ç‚¹è¿›è¡Œåˆ†å‰²"""
    global clicked_points, original_image
    
    # ä½¿ç”¨åŸå§‹å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œè€Œä¸æ˜¯å¸¦æ ‡è®°ç‚¹çš„æ˜¾ç¤ºå›¾åƒ
    if original_image is None:
        return None, None, "è¯·å…ˆä¸Šä¼ å›¾åƒ"
    
    # ä¼˜å…ˆä½¿ç”¨å…¨å±€ç‚¹å‡»ç‚¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™è§£æåæ ‡æ–‡æœ¬
    click_points = []
    
    if clicked_points:
        # ä½¿ç”¨å…¨å±€ç‚¹å‡»ç‚¹
        click_points = clicked_points.copy()
    elif click_coords_text and click_coords_text.strip():
        # è§£æåæ ‡æ–‡æœ¬ä½œä¸ºå¤‡ç”¨
        try:
            coords_text = click_coords_text.strip()
            
            if coords_text.startswith('[') and coords_text.endswith(']'):
                # å¤šç‚¹æ ¼å¼: [(100,200), (300,400)]
                import ast
                coords_list = ast.literal_eval(coords_text)
                for coord in coords_list:
                    if isinstance(coord, (list, tuple)) and len(coord) >= 2:
                        click_points.append([float(coord[0]), float(coord[1])])
            elif '(' in coords_text:
                # å•ç‚¹æ ¼å¼: (100, 200)
                coords_text = coords_text.replace('(', '').replace(')', '')
                parts = coords_text.split(',')
                if len(parts) >= 2:
                    click_points.append([float(parts[0].strip()), float(parts[1].strip())])
            else:
                # ç®€å•æ ¼å¼: 100,200
                parts = coords_text.split(',')
                if len(parts) >= 2:
                    click_points.append([float(parts[0].strip()), float(parts[1].strip())])
                
        except Exception as e:
            return None, None, f"åæ ‡æ ¼å¼é”™è¯¯: {e}"
    
    # ä½¿ç”¨åŸå§‹å›¾åƒï¼ˆæ— æ ‡è®°ç‚¹ï¼‰è¿›è¡Œåˆ†å‰²
    success, message = sam_processor.set_image(original_image)
    if not success:
        return None, None, f"å›¾åƒè®¾ç½®å¤±è´¥: {message}"
    
    # å¦‚æœæœ‰ç‚¹å‡»ç‚¹ï¼Œä¼˜å…ˆç‚¹å¼•å¯¼åˆ†å‰²ï¼›å¦åˆ™è‡ªåŠ¨åˆ†å‰²
    if click_points:
        masks, scores, message = sam_processor.predict_with_points(click_points)
        coords_info = f"ä½¿ç”¨åæ ‡ç‚¹: {click_points}" if len(click_points) <= 3 else f"ä½¿ç”¨{len(click_points)}ä¸ªåæ ‡ç‚¹"
        message = f"{message} | {coords_info}"
    else:
        # è‡ªåŠ¨åˆ†å‰²åªè¿”å›ä¸€ä¸ªç»“æœï¼Œè½¬æ¢ä¸ºå¤šç»“æœæ ¼å¼
        mask, score, auto_message = sam_processor.auto_segment(sam_processor.current_image)
        if mask is not None:
            masks = [mask]
            scores = [score]
            message = f"{auto_message} | ä½¿ç”¨è‡ªåŠ¨åˆ†å‰²"
        else:
            return None, None, None, None, f"åˆ†å‰²å¤±è´¥: {auto_message}"
    
    if masks is not None and len(masks) > 0:
        # ç”Ÿæˆå¤šä¸ªåˆ†å‰²ç»“æœ
        result_images = []
        for i, (mask, score) in enumerate(zip(masks, scores)):
            result_img = apply_mask_to_image(sam_processor.current_image, mask, True)
            result_images.append(result_img)
        
        # åˆ›å»ºå åŠ å›¾åƒ
        overlay_image = create_overlay_image(sam_processor.current_image, masks, scores)
        
        # ç¡®ä¿è¿”å›3ä¸ªç»“æœï¼Œä¸è¶³çš„ç”¨Noneå¡«å……
        while len(result_images) < 3:
            result_images.append(None)
        
        status_msg = f"åˆ†å‰²å®Œæˆ! ç”Ÿæˆ{len(masks)}ä¸ªå€™é€‰ç»“æœ + 1ä¸ªå¹¶é›†ç»“æœ"
        if click_points:
            status_msg += f" | {coords_info}"
        
        return result_images[0], result_images[1], result_images[2], overlay_image, status_msg
    else:
        return None, None, None, None, f"åˆ†å‰²å¤±è´¥: {message}"

def create_overlay_image(original_image, masks, scores):
    """åˆ›å»ºæ‰€æœ‰æ©ç çš„å¹¶é›†ï¼ˆunionï¼‰åˆ†å‰²ç»“æœ"""
    if masks is None or len(masks) == 0:
        return original_image
    
    # åˆ›å»ºå¹¶é›†æ©ç ï¼šæ‰€æœ‰maskçš„é€»è¾‘æˆ–è¿ç®—
    union_mask = np.zeros_like(masks[0], dtype=bool)
    for mask in masks:
        union_mask = union_mask | mask
    
    # åº”ç”¨å¹¶é›†æ©ç åˆ°åŸå§‹å›¾åƒ
    result_image = apply_mask_to_image(original_image, union_mask, True)
    
    return result_image

# å…¨å±€å˜é‡å­˜å‚¨ç‚¹å‡»ç‚¹å’ŒåŸå§‹å›¾åƒ
clicked_points = []
original_image = None

def handle_image_click(image, evt: gr.SelectData):
    """å¤„ç†å›¾åƒç‚¹å‡»äº‹ä»¶ï¼Œç´¯ç§¯ç‚¹å‡»åæ ‡å¹¶åœ¨å›¾åƒä¸Šæ˜¾ç¤º"""
    global clicked_points, original_image
    
    if image is None:
        return image, ""
    
    # ä¿å­˜åŸå§‹å›¾åƒï¼ˆæ— æ ‡è®°ç‚¹ç‰ˆæœ¬ï¼‰
    if original_image is None or len(clicked_points) == 0:
        original_image = image.copy()
    
    x, y = evt.index[0], evt.index[1]
    clicked_points.append([x, y])
    
    # åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ‰€æœ‰ç‚¹å‡»ç‚¹
    image_with_points = draw_points_on_image(original_image, clicked_points)
    
    # æ ¼å¼åŒ–åæ ‡æ–‡æœ¬
    if len(clicked_points) == 1:
        coords_text = f"({clicked_points[0][0]}, {clicked_points[0][1]})"
    else:
        coords_text = str(clicked_points)
    
    return image_with_points, coords_text

def draw_points_on_image(image, points):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶ç‚¹å‡»ç‚¹"""
    if image is None or not points:
        return image
    
    # å¤åˆ¶å›¾åƒé¿å…ä¿®æ”¹åŸå›¾
    image_copy = image.copy()
    
    # ç»˜åˆ¶æ¯ä¸ªç‚¹å‡»ç‚¹
    for i, (x, y) in enumerate(points):
        # ç»˜åˆ¶çº¢è‰²åœ†ç‚¹
        cv2.circle(image_copy, (int(x), int(y)), 8, (255, 0, 0), -1)  # çº¢è‰²å®å¿ƒåœ†
        cv2.circle(image_copy, (int(x), int(y)), 10, (255, 255, 255), 2)  # ç™½è‰²è¾¹æ¡†
        
        # æ·»åŠ ç‚¹ç¼–å·
        cv2.putText(image_copy, str(i+1), (int(x)+12, int(y)-12), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    return image_copy

def clear_points_and_restore_image():
    """æ¸…é™¤æ‰€æœ‰ç‚¹å‡»ç‚¹å¹¶æ¢å¤åŸå§‹å›¾åƒ"""
    global clicked_points, original_image
    clicked_points = []
    restored_image = original_image.copy() if original_image is not None else None
    return restored_image, "", "å·²æ¸…é™¤æ‰€æœ‰ç‚¹å‡»ç‚¹"

def reset_image_to_original(new_image):
    """é‡ç½®å›¾åƒåˆ°åŸå§‹çŠ¶æ€ï¼ˆæ— ç‚¹å‡»ç‚¹æ ‡è®°ï¼‰"""
    global clicked_points, original_image
    clicked_points = []
    original_image = new_image.copy() if new_image is not None else None
    return new_image, ""

def create_sam_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(title="SAMæ™ºèƒ½æŠ å›¾å·¥å…·", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ¯ SAMæ™ºèƒ½æŠ å›¾å·¥å…·
        
        åŸºäºMetaçš„Segment Anything Modelå®ç°çš„æ™ºèƒ½æŠ å›¾å·¥å…·
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ”§ æ¨¡å‹è®¾ç½®")
                
                model_type = gr.Dropdown(
                    choices=["vit_b", "vit_l", "vit_h"],
                    value="vit_b",
                    label="æ¨¡å‹ç±»å‹",
                    info="vit_b: å¿«é€Ÿ, vit_l: å¹³è¡¡, vit_h: é«˜ç²¾åº¦"
                )
                
                load_btn = gr.Button("åŠ è½½æ¨¡å‹", variant="primary")
                model_status = gr.Textbox(
                    label="æ¨¡å‹çŠ¶æ€",
                    value="æ¨¡å‹æœªåŠ è½½",
                    interactive=False
                )
                
                gr.Markdown("### ğŸ’¡ ä½¿ç”¨æ–¹æ³•")
                gr.Markdown("""
                1. åŠ è½½SAMæ¨¡å‹
                2. ä¸Šä¼ å›¾åƒå¹¶ç‚¹å‡»è¦åˆ†å‰²çš„åŒºåŸŸ
                3. ç‚¹å‡»"æ‰§è¡Œåˆ†å‰²"æŸ¥çœ‹3ä¸ªå€™é€‰ç»“æœ
                
                **ç‰¹è‰²åŠŸèƒ½ï¼š**
                - ğŸ¯ æ˜¾ç¤º3ä¸ªå€™é€‰åˆ†å‰²ç»“æœ
                - ğŸ”— è‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰ç»“æœçš„å¹¶é›†
                - ğŸ“Š æ˜¾ç¤ºæ¯ä¸ªç»“æœçš„ç½®ä¿¡åº¦
                """)
                
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ–±ï¸ äº¤äº’å¼åˆ†å‰²")
                
                # ç»Ÿä¸€çš„å›¾åƒç»„ä»¶ï¼Œæ—¢èƒ½ä¸Šä¼ åˆèƒ½ç‚¹å‡»
                interactive_image = gr.Image(
                    label="ä¸Šä¼ å›¾åƒå¹¶ç‚¹å‡»é€‰æ‹©è¦åˆ†å‰²çš„åŒºåŸŸ",
                    type="numpy",
                    sources=["upload", "clipboard"],
                    interactive=True
                )
                
                with gr.Row():
                    clear_btn = gr.Button("æ¸…é™¤ç‚¹å‡»ç‚¹", variant="secondary")
                    segment_btn = gr.Button("æ‰§è¡Œåˆ†å‰²", variant="primary")
                
                # åæ ‡æ˜¾ç¤ºå’Œç¼–è¾‘
                click_coords = gr.Textbox(
                    label="ç‚¹å‡»åæ ‡",
                    placeholder="ç‚¹å‡»å›¾åƒåä¼šæ˜¾ç¤ºåæ ‡ï¼Œä¹Ÿå¯æ‰‹åŠ¨è¾“å…¥",
                    interactive=True,
                    lines=2
                )
                
                process_status = gr.Textbox(
                    label="å¤„ç†çŠ¶æ€",
                    interactive=False
                )
        
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ¨ å€™é€‰ç»“æœ 1")
                result_image_1 = gr.Image(
                    label="å€™é€‰ç»“æœ 1ï¼ˆæœ€ä½³ï¼‰",
                    type="numpy"
                )
                
            with gr.Column():
                gr.Markdown("### ğŸ¨ å€™é€‰ç»“æœ 2") 
                result_image_2 = gr.Image(
                    label="å€™é€‰ç»“æœ 2",
                    type="numpy"
                )
                
        with gr.Row():
            with gr.Column():
                gr.Markdown("### ğŸ¨ å€™é€‰ç»“æœ 3")
                result_image_3 = gr.Image(
                    label="å€™é€‰ç»“æœ 3",
                    type="numpy"
                )
                
            with gr.Column():
                gr.Markdown("### ğŸ”— åˆå¹¶ç»“æœ")
                overlay_image = gr.Image(
                    label="æ‰€æœ‰å€™é€‰ç»“æœçš„å¹¶é›†ï¼ˆUnionï¼‰",
                    type="numpy"
                )
        
        with gr.Row():
            gr.Markdown("ğŸ’¡ é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦å‡ ç™¾MBï¼‰ï¼Œæ”¯æŒGPUåŠ é€Ÿ")
        
        # äº‹ä»¶ç»‘å®š
        load_btn.click(
            fn=load_sam_model,
            inputs=[model_type],
            outputs=[model_status]
        )
        
        # å¤„ç†å›¾åƒç‚¹å‡»äº‹ä»¶ - ç´¯ç§¯ç‚¹å‡»å¹¶å®æ—¶æ˜¾ç¤º
        interactive_image.select(
            fn=handle_image_click,
            inputs=[interactive_image],
            outputs=[interactive_image, click_coords]
        )
        
        # æ¸…é™¤ç‚¹å‡»ç‚¹å¹¶æ¢å¤åŸå§‹å›¾åƒ
        clear_btn.click(
            fn=clear_points_and_restore_image,
            outputs=[interactive_image, click_coords, process_status]
        )
        
        # å½“ä¸Šä¼ æ–°å›¾åƒæ—¶ï¼Œé‡ç½®ç‚¹å‡»ç‚¹
        interactive_image.upload(
            fn=reset_image_to_original,
            inputs=[interactive_image],
            outputs=[interactive_image, click_coords]
        )
        
        # æ‰§è¡Œåˆ†å‰²
        segment_btn.click(
            fn=segment_with_points,
            inputs=[interactive_image, click_coords],
            outputs=[result_image_1, result_image_2, result_image_3, overlay_image, process_status]
        )
    
    return demo

def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
    os.makedirs("models", exist_ok=True)
    os.makedirs("uploads", exist_ok=True)
    
    # åˆ›å»ºç•Œé¢
    demo = create_sam_interface()
    
    # å¯åŠ¨æœåŠ¡
    demo.launch(
        server_name="0.0.0.0",
        server_port=8002,
        share=False,
        show_error=True,
        quiet=False
    )

if __name__ == "__main__":
    main()
